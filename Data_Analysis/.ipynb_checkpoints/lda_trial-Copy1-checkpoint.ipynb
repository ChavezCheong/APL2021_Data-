{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out an LDA model to apply topic modelling to MEAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\chave\\anaconda3\\envs\\topicmodelling\\lib\\site-packages (1.21.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chave\\anaconda3\\envs\\topicmodelling\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Handle imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "import pickle\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string\n",
    "import pprint\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('transformer', <spacy_transformers.pipeline_component.Transformer object at 0x000001431641EFA8>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x000001430DDDB6A8>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x0000014316446C18>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x000001430DDE53C8>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x00000143162D6D88>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x0000014316446D68>)]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_trf')\n",
    "lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.update([\"ohio\",\"division\", \"department\", \"commerce\",\"financial\",\"revised\",\"code\",\"institutions\",\"chapter\",\"codified\",\"institution\"])\n",
    "# Iterates over the words in the stop words list and resets the \"is_stop\" flag.\n",
    "for word in STOP_WORDS:\n",
    "    lexeme = nlp.vocab[word]\n",
    "    lexeme.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"Standardized Data/Final_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sample_text):\n",
    "    sample_text = sample_text.translate(str.maketrans('', '', string.punctuation))\n",
    "    sample_text = \" \".join([w for w in sample_text.split() if not w.isdigit()])\n",
    "    sample_text = sample_text.lower()\n",
    "    doc = nlp(sample_text)\n",
    "    doc = [token.lemma_ for token in doc if token.lemma_ != '-PRON-']\n",
    "    doc = u' '.join(doc)\n",
    "    doc = nlp.make_doc(doc)\n",
    "    tokens = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['charge', 'responsibility', 'enforce', 'mortgage', 'loan', 'act', 'codify', 'rc', 'protect', 'public', 'proscribed', 'mortgage', 'lending', 'practice', 'find', 'order', 'necessary', 'appropriate', 'interest', 'public', 'consistent', 'purpose', 'mortgage', 'loan', 'act', 'aj', 'investments', 'inc', 'dba', 'aj', 'fund', 'respondent', 'corporation', 'register', 'mortgage', 'lender', 'pursuant', 'rc', 'fail', 'renew', 'registration', 'period', 'begin', 'july', 'business', 'address', 'record', 'respondent', 'east', '34th', 'street', 'willoughby', 'june', 'serve', 'respondent', 'certified', 'mail', 'notice', 'divisions', 'intent', 'revoke', 'respondent', 'mortgage', 'lender', 'certificate', 'registration', 'notice', 'respondent', 'right', 'hearing', 'matter', 'notice', 'pursuant', 'rc', 'notice', 'state', 'respondent', 'notify', 'entitled', 'adjudicative', 'hearing', 'request', 'thirty', 'day', 'date', 'mail', 'notice', 'respondent', 'request', 'hearing', 'thirty', 'day', 'date', 'mailing', 'notice', 'issue', 'order', 'revoke', 'mortgage', 'lender', 'certificate', 'registration', 'aj', 'investments', 'inc', 'dba', 'aj', 'funding', 'aj', 'investment', 'inc', 'dba', 'aj', 'funding', 'order', '01sm02', 'page', 'respondent', 'fail', 'request', 'hearing', 'fail', 'defend', 'divisions', 'allegation', 'respondent', 'meet', 'net', 'worth', 'requirement', 'registration', 'mandate', 'rc', '132153b', 'find', 'allegation', 'contain', 'notice', 'true', 'order', 'pursuant', 'rc', 'chapters', 'respondent', 'mortgage', 'lender', 'certificate', 'registration', 'revoke']\n"
     ]
    }
   ],
   "source": [
    "sample_text = df.loc[3,\"Text\"]\n",
    "print(clean_text(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chave\\anaconda3\\envs\\topicmodelling\\lib\\site-packages\\ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59757b0f358436aa5ef4603b05b6d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = df[\"Text\"][:10]\n",
    "text_list = []\n",
    "for doc in tqdm(text):\n",
    "    if not pd.isna(doc):\n",
    "        pr = clean_text(doc)\n",
    "        text_list.append(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['charge',\n",
       " 'responsibility',\n",
       " 'enforce',\n",
       " 'mortgage',\n",
       " 'broker',\n",
       " 'act',\n",
       " 'codify',\n",
       " 'rc',\n",
       " 'protect',\n",
       " 'public',\n",
       " 'proscribed',\n",
       " 'mortgage',\n",
       " 'lending',\n",
       " 'practice',\n",
       " 'find',\n",
       " 'order',\n",
       " 'necessary',\n",
       " 'appropriate',\n",
       " 'interest',\n",
       " 'public',\n",
       " 'consistent',\n",
       " 'purpose',\n",
       " 'mortgage',\n",
       " 'broker',\n",
       " 'act',\n",
       " 'mortgage',\n",
       " 'specialists',\n",
       " 'inc',\n",
       " 'respondent',\n",
       " 'kentucky',\n",
       " 'corporation',\n",
       " 'renew',\n",
       " 'certificate',\n",
       " 'registration',\n",
       " 'period',\n",
       " 'april',\n",
       " 'mortgage',\n",
       " 'broker',\n",
       " 'pursuant',\n",
       " 'rc',\n",
       " 'return',\n",
       " 'certificate',\n",
       " 'september',\n",
       " 'business',\n",
       " 'address',\n",
       " 'record',\n",
       " 'respondent',\n",
       " 'john',\n",
       " 'sutherland',\n",
       " 'drive',\n",
       " 'suite',\n",
       " 'nicholasville',\n",
       " 'ky',\n",
       " 'july',\n",
       " 'serve',\n",
       " 'respondent',\n",
       " 'certified',\n",
       " 'mail',\n",
       " 'notice',\n",
       " 'divisions',\n",
       " 'intent',\n",
       " 'revoke',\n",
       " 'respondent',\n",
       " 'mortgage',\n",
       " 'broker',\n",
       " 'certificate',\n",
       " 'registration',\n",
       " 'notice',\n",
       " 'respondent',\n",
       " 'right',\n",
       " 'hearing',\n",
       " 'matter',\n",
       " 'notice',\n",
       " 'pursuant',\n",
       " 'rc',\n",
       " 'notice',\n",
       " 'state',\n",
       " 'respondent',\n",
       " 'notify',\n",
       " 'entitled',\n",
       " 'adjudicative',\n",
       " 'hearing',\n",
       " 'request',\n",
       " 'thirty',\n",
       " 'day',\n",
       " 'date',\n",
       " 'mail',\n",
       " 'notice',\n",
       " 'respondent',\n",
       " 'request',\n",
       " 'hearing',\n",
       " 'thirty',\n",
       " 'day',\n",
       " 'date',\n",
       " 'mailing',\n",
       " 'notice',\n",
       " 'issue',\n",
       " 'order',\n",
       " 'revoke',\n",
       " 'mortgage',\n",
       " 'broker',\n",
       " 'certificates',\n",
       " 'registration',\n",
       " 'mortgage',\n",
       " 'specialists',\n",
       " 'inc',\n",
       " 'mortgage',\n",
       " 'specialists',\n",
       " 'inc',\n",
       " 'order',\n",
       " '01mb25',\n",
       " 'page',\n",
       " 'respondent',\n",
       " 'fail',\n",
       " 'request',\n",
       " 'hearing',\n",
       " 'fail',\n",
       " 'defend',\n",
       " 'divisions',\n",
       " 'allegation',\n",
       " 'respondent',\n",
       " 'violate',\n",
       " 'rc',\n",
       " 'substantial',\n",
       " 'misrepresentation',\n",
       " 'respondent',\n",
       " 'renewal',\n",
       " 'application',\n",
       " 'obtain',\n",
       " 'mortgage',\n",
       " 'broker',\n",
       " 'certificate',\n",
       " 'registration',\n",
       " 'false',\n",
       " 'fraudulent',\n",
       " 'representation',\n",
       " 'find',\n",
       " 'allegation',\n",
       " 'contain',\n",
       " 'notice',\n",
       " 'true',\n",
       " 'order',\n",
       " 'pursuant',\n",
       " 'rc',\n",
       " 'respondent',\n",
       " 'mortgage',\n",
       " 'broker',\n",
       " 'certificate',\n",
       " 'registration',\n",
       " 'revoke']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates, which is a mapping of word IDs to words.\n",
    "words = corpora.Dictionary(text_list)\n",
    "\n",
    "# Turns each document into a bag of words.\n",
    "corpus = [words.doc2bow(doc) for doc in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=words,\n",
    "                                           num_topics=5 \n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Kernel is dead",
     "output_type": "error",
     "traceback": [
      "Error: Kernel is dead",
      "at g._sendKernelShellControl (c:\\Users\\chave\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1054968649\\out\\client\\extension.js:52:852938)",
      "at g.sendShellMessage (c:\\Users\\chave\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1054968649\\out\\client\\extension.js:52:852707)",
      "at g.requestExecute (c:\\Users\\chave\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1054968649\\out\\client\\extension.js:52:855249)",
      "at d.requestExecute (c:\\Users\\chave\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1054968649\\out\\client\\extension.js:37:313885)",
      "at w.requestExecute (c:\\Users\\chave\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1054968649\\out\\client\\extension.js:24:134487)",
      "at w.executeCodeCell (c:\\Users\\chave\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1054968649\\out\\client\\extension.js:90:319834)",
      "at w.execute (c:\\Users\\chave\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1054968649\\out\\client\\extension.js:90:319389)",
      "at w.start (c:\\Users\\chave\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1054968649\\out\\client\\extension.js:90:315205)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\chave\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1054968649\\out\\client\\extension.js:90:329732)",
      "at async t.CellExecutionQueue.start (c:\\Users\\chave\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1054968649\\out\\client\\extension.js:90:329272)"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c200356685012de8850201f95537ce902c61c8fd611b23a6f6394b46e0ce5b2e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
